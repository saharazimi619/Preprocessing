{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr181a3DxyZoTYwhz8Lo2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saharazimi619/Preprocessing/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGF6VH1YdtvX",
        "outputId": "25e82f57-c6c9-4a34-8074-cf5009f0b518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"Machine learning is a field of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves. The primary aim of machine learning is to allow computers to learn automatically without human intervention or assistance and adjust actions accordingly.\n",
        "Machine learning algorithms use computational methods to 'learn' information directly from data without relying on a predetermined equation as a model. The algorithms adaptively improve their performance as the number of samples available for learning increases. Machine learning is closely related to and often overlaps with computational statistics, which also focuses on prediction-making through the use of computers. It has strong ties to mathematical optimization, which delivers methods, theory and application domains to the field.\"\"\"\n"
      ],
      "metadata": {
        "id": "R99KxTegeGRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing sentences\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxLIjhL6h13p",
        "outputId": "9e6d992b-4a74-4bb8-a880-86094e79c36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Machine learning is a field of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed.',\n",
              " 'It focuses on the development of computer programs that can access data and use it to learn for themselves.',\n",
              " 'The primary aim of machine learning is to allow computers to learn automatically without human intervention or assistance and adjust actions accordingly.',\n",
              " \"Machine learning algorithms use computational methods to 'learn' information directly from data without relying on a predetermined equation as a model.\",\n",
              " 'The algorithms adaptively improve their performance as the number of samples available for learning increases.',\n",
              " 'Machine learning is closely related to and often overlaps with computational statistics, which also focuses on prediction-making through the use of computers.',\n",
              " 'It has strong ties to mathematical optimization, which delivers methods, theory and application domains to the field.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing words\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9lX16-zigNJ",
        "outputId": "fc831ccf-c06c-4dd8-afcd-58ce3e01ff7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Machine',\n",
              " 'learning',\n",
              " 'is',\n",
              " 'a',\n",
              " 'field',\n",
              " 'of',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'that',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'and',\n",
              " 'improve',\n",
              " 'from',\n",
              " 'experience',\n",
              " 'without',\n",
              " 'being',\n",
              " 'explicitly',\n",
              " 'programmed',\n",
              " '.',\n",
              " 'It',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'the',\n",
              " 'development',\n",
              " 'of',\n",
              " 'computer',\n",
              " 'programs',\n",
              " 'that',\n",
              " 'can',\n",
              " 'access',\n",
              " 'data',\n",
              " 'and',\n",
              " 'use',\n",
              " 'it',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'for',\n",
              " 'themselves',\n",
              " '.',\n",
              " 'The',\n",
              " 'primary',\n",
              " 'aim',\n",
              " 'of',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'is',\n",
              " 'to',\n",
              " 'allow',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'automatically',\n",
              " 'without',\n",
              " 'human',\n",
              " 'intervention',\n",
              " 'or',\n",
              " 'assistance',\n",
              " 'and',\n",
              " 'adjust',\n",
              " 'actions',\n",
              " 'accordingly',\n",
              " '.',\n",
              " 'Machine',\n",
              " 'learning',\n",
              " 'algorithms',\n",
              " 'use',\n",
              " 'computational',\n",
              " 'methods',\n",
              " 'to',\n",
              " \"'learn\",\n",
              " \"'\",\n",
              " 'information',\n",
              " 'directly',\n",
              " 'from',\n",
              " 'data',\n",
              " 'without',\n",
              " 'relying',\n",
              " 'on',\n",
              " 'a',\n",
              " 'predetermined',\n",
              " 'equation',\n",
              " 'as',\n",
              " 'a',\n",
              " 'model',\n",
              " '.',\n",
              " 'The',\n",
              " 'algorithms',\n",
              " 'adaptively',\n",
              " 'improve',\n",
              " 'their',\n",
              " 'performance',\n",
              " 'as',\n",
              " 'the',\n",
              " 'number',\n",
              " 'of',\n",
              " 'samples',\n",
              " 'available',\n",
              " 'for',\n",
              " 'learning',\n",
              " 'increases',\n",
              " '.',\n",
              " 'Machine',\n",
              " 'learning',\n",
              " 'is',\n",
              " 'closely',\n",
              " 'related',\n",
              " 'to',\n",
              " 'and',\n",
              " 'often',\n",
              " 'overlaps',\n",
              " 'with',\n",
              " 'computational',\n",
              " 'statistics',\n",
              " ',',\n",
              " 'which',\n",
              " 'also',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'prediction-making',\n",
              " 'through',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'computers',\n",
              " '.',\n",
              " 'It',\n",
              " 'has',\n",
              " 'strong',\n",
              " 'ties',\n",
              " 'to',\n",
              " 'mathematical',\n",
              " 'optimization',\n",
              " ',',\n",
              " 'which',\n",
              " 'delivers',\n",
              " 'methods',\n",
              " ',',\n",
              " 'theory',\n",
              " 'and',\n",
              " 'application',\n",
              " 'domains',\n",
              " 'to',\n",
              " 'the',\n",
              " 'field',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-21kucZjbyQ",
        "outputId": "1c3a0f22-3ab0-469b-e168-8334f824fc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "#stemming\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "uff5lGf5j0gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rWufZTzFlt_6",
        "outputId": "1d9766dc-e99e-47b7-bc9a-27f46c992f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'it focus develop comput program access data use learn .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D043CXPBmCJz",
        "outputId": "0292b672-62b3-40e2-956c-ffde58557149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "sentencess = nltk.sent_tokenize(paragraph)\n",
        "#lemmatization\n",
        "for i in range(len(sentencess)):\n",
        "  words = nltk.word_tokenize(sentencess[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentencess[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "VL-fe__8mXVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentencess[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oDyELQTcm-B4",
        "outputId": "7bd23b24-8e3d-4c6d-d802-90fc6d6f08b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It focus development computer program access data use learn .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning the texts\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "ps = PorterStemmer()\n",
        "wordnet = WordNetLemmatizer()\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "corpus = []\n",
        "for i in range(len(sentences)):\n",
        "  review = re.sub('[^a_zA_Z]',' ',sentences[i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "#creating the bag of words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "X = cv.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "ZYvR4sVfoLms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKtfD6s_y_wY",
        "outputId": "7bdae030-86a0-42d6-d336-07cd9c4b058b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentencess = nltk.sent_tokenize(paragraph)\n",
        "corpus = []\n",
        "for i in range(len(sentences)):\n",
        "  review = re.sub('[^a_zA_Z]',' ',sentencess[i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "#creating the TF_IDF model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer()\n",
        "X = tf.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "kxDRAU82zPYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1OzZLQO00W4",
        "outputId": "06ddf6a5-940e-41b3-ed0a-1a1658a02b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}